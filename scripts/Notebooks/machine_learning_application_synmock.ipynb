{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application of Machine Learning to Synthetic Mock Community (Validation Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REQUIRED PACKAGES\n",
    "# argparse, Biopython, json, keras, math, matplotlib, numpy, os, pandas, random, scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv1D, Dropout, MaxPooling1D, Flatten\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "# Extract the reference for the taxa\n",
    "def getquery_taxfileid(ref_df, species):\n",
    "    \"\"\"\n",
    "    Takes the reference dataframe filename and the species name.\n",
    "    Returns the taxfileid, which is the date/flowcellid (column 0 value) of the ref_df.\n",
    "    \"\"\"\n",
    "    return ref_df[ref_df.species == species].iloc[:,0].values[0]\n",
    "\n",
    "# Returns the taxonomic assignment at each rank as the expected output for comparison to the decision tree's predicted output\n",
    "def get_taxid_dict(taxid_fn, taxfileid):\n",
    "    \"\"\"\n",
    "    Takes a taxonomy assignment file filename in the Qiime format and a taxonomic identifier.\n",
    "    Returns the a dictionary with the taxonomic assignment at each rank.\n",
    "    \"\"\"\n",
    "    tax_dict = {}\n",
    "    with open(taxid_fn, 'r') as fh:\n",
    "        for line in fh:\n",
    "            if line.startswith(taxfileid):\n",
    "                taxrankids = line.rstrip().split('\\t')[1].split(';')\n",
    "                for taxrank in taxrankids:\n",
    "                    tax_dict[taxrank.split('__')[0]] = taxrank.split('__')[1]\n",
    "    return tax_dict\n",
    "\n",
    "# Convert nucleic data to numerical data and pad sequence to pad_length for use with the validation dataset\n",
    "def numberfy(SeqIO_dict, seq_len, nsubsample, species_name, pad_length):\n",
    "    \"\"\"\n",
    "    Take SeqIO_dict and return SeqIO_dict were bases have been replaced\n",
    "    with numbers\n",
    "    ACGT- replaced with 01234\n",
    "    Take the seq_len each sequence should have\n",
    "    \"\"\"\n",
    "    num_dict = {}\n",
    "    \n",
    "    randkeys = [SeqIO_dict.id]\n",
    "#     print(randkeys)\n",
    "    \n",
    "    for key in randkeys:\n",
    "        seq = str(SeqIO_dict.seq).replace(\"A\",'0 ')\\\n",
    "        .replace(\"C\",'1 ').replace(\"G\",'2 ').replace(\"T\",'3 ')\\\n",
    "        .replace(\"a\",'0 ').replace(\"c\",'1 ').replace(\"g\",'2 ')\\\n",
    "        .replace(\"t\",'3 ')\n",
    "#         seq_new = seq + '4 '*(seq_len - int(len(seq)/2))\n",
    "        seq_new = seq + '4 '*(pad_length - int(len(seq)/2))\n",
    "        if seq_new.find('t') != -1:\n",
    "            print(seq_new.find('t'))\n",
    "            print(\"ERROR - strange value in sequence\")\n",
    "            print(seq_new)\n",
    "            exit()\n",
    "        num_dict[key] = list(map(int, seq_new.split(' ')[:-1]))\n",
    "    return num_dict\n",
    "\n",
    "\n",
    "\n",
    "## Load the required files\n",
    "# File with the taxonomy for each taxa in the mock community \n",
    "mock_taxonomy_file_fn = os.path.abspath('/media/MassStorage/tmp/TE/honours/analysis/Stats/mock_taxonomy_file_qiime.csv')\n",
    "tax_ranks = ['kingdom',\n",
    "             'phylum',\n",
    "             'class', 'order', 'family', 'genus'\n",
    "            ]\n",
    "# List of nodes where models are located\n",
    "nodes = pd.read_csv('../../analysis/Stats/nodes.csv', sep=' ', header=None)\n",
    "nodes.columns = ['tax_rank','tax_name']\n",
    "# Reference dataframes and dictionaries containing taxonomic information\n",
    "ref_df = pd.read_csv('../../analysis/Stats/mock_reference_dataframe.csv', index_col=None)\n",
    "large_ref_df = pd.read_csv('../../analysis/Stats/large_mock_reference_dataframe.csv', index_col=None)\n",
    "full_mock_dict = SeqIO.to_dict(SeqIO.parse(\"../../analysis/Mapping/mock/subsample_reads/mock_community_1000.fasta\", \"fasta\"))\n",
    "# Define variable numbers\n",
    "n_per_species = 1000.\n",
    "pad_length = 5000\n",
    "\n",
    "# Define the species in mock community and assign them a dictionary of taxonomic counters\n",
    "species_list = []\n",
    "for key in full_mock_dict:\n",
    "    if full_mock_dict[key].description.split(' ')[1] not in species_list:\n",
    "        species_list.append(full_mock_dict[key].description.split(' ')[1])\n",
    "all_values_dict = {}\n",
    "\n",
    "for species in species_list:\n",
    "    taxfileid = getquery_taxfileid(ref_df, species)\n",
    "    query_tax_dict = get_taxid_dict(mock_taxonomy_file_fn, taxfileid)\n",
    "    all_values_dict[species] = query_tax_dict,{'k': 0, 'p': 0, 'c': 0, 'o': 0, 'f': 0, 'g': 0, 's': 0}\n",
    "# print(all_values_dict)\n",
    "        \n",
    "    \n",
    "# For each input read, run through the following:\n",
    "#    Convert nucleic data to numeric data and pad to the sequence length\n",
    "#    Define the data as the validation set and define the expected labels\n",
    "#    For each taxonomic rank, load the appropriate model and input the read to the model. If the tax rank is not a node, pass to the next tax rank\n",
    "#    Compare the predicted and expected outputs. If they match, add 1/n_per_species to the counter for that taxa for the specific taxonomic rank\n",
    "#    This counts the proportion of predicted outputs that match the expected output at each taxonomic rank\n",
    "# Once all reads for a specific taxa have been assessed, save the validation accuracy as a json file\n",
    "\n",
    "\n",
    "for i in range(0, len(full_mock_dict.keys())):\n",
    "    # Print progress markers for clarity of display\n",
    "    print('%s/%s' % (i+1,len(full_mock_dict.keys())))\n",
    "    key = list(full_mock_dict.keys())[i]\n",
    "    species_name = full_mock_dict[key].description.split(' ')[1]\n",
    "    if i == 0 or i % n_per_species == 0:\n",
    "        print(species_name)\n",
    "    max_len = len(full_mock_dict[key].seq)\n",
    "\n",
    "    # convert base pair coding to numerical coding and \n",
    "    # pad to the max sequence length\n",
    "    n_reads = 1\n",
    "    \n",
    "    numSeqIO_dicts = {}\n",
    "    numSeqIO_dicts[key] = numberfy(full_mock_dict[key], max_len, n_reads, species_name, pad_length)\n",
    "    seq_list = []\n",
    "    for key in numSeqIO_dicts.keys():\n",
    "        seq_list.append(np.array(list(numSeqIO_dicts[key].values())))\n",
    "\n",
    "    all_data = np.concatenate(seq_list)\n",
    "    num_class = len(numSeqIO_dicts)\n",
    "\n",
    "    \n",
    "    samples_count = n_reads*num_class\n",
    "\n",
    "    \n",
    "    \n",
    "    # # Assign all reads as part of the validation set\n",
    "    valid_size = math.floor(1*all_data.shape[0])\n",
    "\n",
    "    # # Define the data vs labels for the validaton set\n",
    "    X_valid = all_data[:,:]\n",
    "\n",
    "    # As all taxa belong to fungal kingdom, add 1/n_per_species to kingdom counter\n",
    "    all_values_dict[species_name][1]['k'] += 1./n_per_species\n",
    "    \n",
    "    # Define a counter to count down the number of taxonomic ranks to assess\n",
    "    counter = 6\n",
    "    for tax_rank in tax_ranks:\n",
    "        if tax_rank == 'kingdom':\n",
    "            # Load the model and output classes, predict the output and compare the predicted output to the expected output\n",
    "            model = load_model('../../analysis/models/model_%s_%s_15000.h5' % (tax_rank, 'fungi'))\n",
    "            classes = pd.read_csv('../../analysis/models/keys_%s_%s_15000.csv' % (tax_rank, 'fungi'), header=None)\n",
    "            classes.columns = ['predict','pred_name']\n",
    "            scores = model.predict(np.expand_dims(X_valid,2))\n",
    "            predicts = model.predict_classes(np.expand_dims(X_valid,2))\n",
    "            predicted_class = classes[classes['predict'] == predicts[0]]['pred_name'].to_list()[0]\n",
    "            # If the predicted output and expected output match, add 1/n_per_species to the counter for this taxonomic rank for this taxa\n",
    "            if ref_df[ref_df.iloc[:,1] == species_name].iloc[:,counter].to_list()[0] == predicted_class:\n",
    "                all_values_dict[species_name][1][ref_df[ref_df.iloc[:,1] == species_name].columns[counter][0]] += 1./n_per_species\n",
    "            counter -= 1\n",
    "            keras.backend.clear_session()\n",
    "            \n",
    "        elif tax_rank == 'genus':\n",
    "            if predicted_class not in nodes['tax_name'].values:\n",
    "                # then add 1/n_per_species to each correct count if correct\n",
    "                predicted_class = large_ref_df[large_ref_df[tax_rank] == predicted_class].iloc[:,counter].to_list()[0]\n",
    "                if ref_df[ref_df.iloc[:,1] == species_name].iloc[:,counter].to_list()[0].split('_')[1] == predicted_class:\n",
    "                    all_values_dict[species_name][1][ref_df[ref_df.iloc[:,1] == species_name].columns[counter][0]] += 1./n_per_species\n",
    "                counter -= 1\n",
    "                keras.backend.clear_session()\n",
    "            else:\n",
    "                # Load the model and output classes, predict the output and compare the predicted output to the expected output\n",
    "                classes = pd.read_csv('../../analysis/models/keys_%s_%s_15000.csv' % (tax_rank, predicted_class), header=None)\n",
    "                classes.columns = ['predict','pred_name']\n",
    "                model = load_model('../../analysis/models/model_%s_%s_15000.h5' % (tax_rank, predicted_class))\n",
    "                scores = model.predict(np.expand_dims(X_valid,2))\n",
    "                predicts = model.predict_classes(np.expand_dims(X_valid,2))\n",
    "                predicted_class = classes[classes['predict'] == predicts[0]]['pred_name'].to_list()[0]\n",
    "                # If the predicted output and expected output match, add 1/n_per_species to the counter for this taxonomic rank for this taxa\n",
    "                if ref_df[ref_df.iloc[:,1] == species_name].iloc[:,counter].to_list()[0].split('_')[1] == predicted_class:\n",
    "                    all_values_dict[species_name][1][ref_df[ref_df.iloc[:,1] == species_name].columns[counter][0]] += 1./n_per_species\n",
    "                counter -= 1\n",
    "                keras.backend.clear_session()\n",
    "                \n",
    "        else:\n",
    "            if predicted_class not in nodes['tax_name'].values:\n",
    "                # then add 1/n_per_species to each correct count if correct\n",
    "                predicted_class = large_ref_df[large_ref_df[tax_rank] == predicted_class].iloc[:,counter].to_list()[0]\n",
    "                if ref_df[ref_df.iloc[:,1] == species_name].iloc[:,counter].to_list()[0] == predicted_class:\n",
    "                    all_values_dict[species_name][1][ref_df[ref_df.iloc[:,1] == species_name].columns[counter][0]] += 1./n_per_species\n",
    "                counter -= 1\n",
    "                keras.backend.clear_session()\n",
    "            else:\n",
    "                # Load the model and output classes, predict the output and compare the predicted output to the expected output\n",
    "                classes = pd.read_csv('../../analysis/models/keys_%s_%s_15000.csv' % (tax_rank, predicted_class), header=None)\n",
    "                classes.columns = ['predict','pred_name']\n",
    "#                 print('../../analysis/models/model_%s_%s_15000.h5' % (tax_rank, predicted_class))\n",
    "                model = load_model('../../analysis/models/model_%s_%s_15000.h5' % (tax_rank, predicted_class))\n",
    "                scores = model.predict(np.expand_dims(X_valid,2))\n",
    "                predicts = model.predict_classes(np.expand_dims(X_valid,2))\n",
    "                predicted_class = classes[classes['predict'] == predicts[0]]['pred_name'].to_list()[0]\n",
    "                # If the predicted output and expected output match, add 1/n_per_species to the counter for this taxonomic rank for this taxa\n",
    "                if ref_df[ref_df.iloc[:,1] == species_name].iloc[:,counter].to_list()[0] == predicted_class:\n",
    "                    all_values_dict[species_name][1][ref_df[ref_df.iloc[:,1] == species_name].columns[counter][0]] += 1./n_per_species\n",
    "                counter -= 1\n",
    "                keras.backend.clear_session()\n",
    "                \n",
    "                \n",
    "    # If all reads for one taxa have ben assessed, print the accuracy of the model's predictions on the validation dataset at each taxonomic rank and save this as a json file\n",
    "    if (i+1) % n_per_species == 0:\n",
    "        print(all_values_dict[species_name][1])\n",
    "        with open('/media/MassStorage/tmp/TE/honours/analysis/Mapping/mock/ML_results/%s.json' % species_name, 'w+') as fp:\n",
    "            json.dump(all_values_dict[species_name][1], fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
