{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application of Machine Learning to Synthetic Mock Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv1D, Dropout, MaxPooling1D, Flatten\n",
    "from keras.utils import plot_model, to_categorical\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getquery_taxfileid(ref_df, species):\n",
    "    \"\"\"\n",
    "    Takes the reference dataframe filename and the species name.\n",
    "    Returns the taxfileid, which is the date/flowcellid (column 0 value) of the ref_df.\n",
    "    \"\"\"\n",
    "    return ref_df[ref_df.species == species].iloc[:,0].values[0]\n",
    "\n",
    "def get_taxid_dict(taxid_fn, taxfileid):\n",
    "    \"\"\"\n",
    "    Takes a taxonomy assignment file filename in the Qiime format and a taxonomic identifier.\n",
    "    Returns the a dictionary with the taxonomic assignment at each rank.\n",
    "    \"\"\"\n",
    "    tax_dict = {}\n",
    "    with open(taxid_fn, 'r') as fh:\n",
    "        for line in fh:\n",
    "            if line.startswith(taxfileid):\n",
    "                taxrankids = line.rstrip().split('\\t')[1].split(';')\n",
    "                for taxrank in taxrankids:\n",
    "                    tax_dict[taxrank.split('__')[0]] = taxrank.split('__')[1]\n",
    "    return tax_dict\n",
    "\n",
    "def numberfy(SeqIO_dict, seq_len, nsubsample, species_name):\n",
    "    \"\"\"\n",
    "    Take SeqIO_dict and return SeqIO_dict were bases have been replaced\n",
    "    with numbers\n",
    "    ACGT- replaced with 01234\n",
    "    Take the seq_len each sequence should have\n",
    "    \"\"\"\n",
    "    num_dict = {}\n",
    "    \n",
    "    randkeys = [SeqIO_dict.id]\n",
    "#     print(randkeys)\n",
    "    \n",
    "    for key in randkeys:\n",
    "        seq = str(SeqIO_dict.seq).replace(\"A\",'0 ')\\\n",
    "        .replace(\"C\",'1 ').replace(\"G\",'2 ').replace(\"T\",'3 ')\\\n",
    "        .replace(\"a\",'0 ').replace(\"c\",'1 ').replace(\"g\",'2 ')\\\n",
    "        .replace(\"t\",'3 ')\n",
    "#         seq_new = seq + '4 '*(seq_len - int(len(seq)/2))\n",
    "        seq_new = seq + '4 '*(5000 - int(len(seq)/2))\n",
    "        if seq_new.find('t') != -1:\n",
    "            print(seq_new.find('t'))\n",
    "            print(\"ERROR - strange value in sequence\")\n",
    "            print(seq_new)\n",
    "            exit()\n",
    "        num_dict[key] = list(map(int, seq_new.split(' ')[:-1]))\n",
    "    return num_dict\n",
    "\n",
    "mock_taxonomy_file_fn = os.path.abspath('/media/MassStorage/tmp/TE/honours/analysis/Stats/mock_taxonomy_file_qiime.csv')\n",
    "tax_ranks = ['kingdom',\n",
    "             'phylum',\n",
    "             'class', 'order', 'family', 'genus'\n",
    "            ]\n",
    "nodes = pd.read_csv('../../analysis/Stats/nodes.csv', sep=' ', header=None)\n",
    "nodes.columns = ['tax_rank','tax_name']\n",
    "ref_df = pd.read_csv('../../analysis/Stats/mock_reference_dataframe.csv', index_col=None)\n",
    "large_ref_df = pd.read_csv('../../analysis/Stats/large_mock_reference_dataframe.csv', index_col=None)\n",
    "full_mock_dict = SeqIO.to_dict(SeqIO.parse(\"../../analysis/Mapping/mock/subsample_reads/mock_community_1000.fasta\", \"fasta\"))\n",
    "n_per_species = 1000.\n",
    "\n",
    "species_list = []\n",
    "for key in full_mock_dict:\n",
    "    if full_mock_dict[key].description.split(' ')[1] not in species_list:\n",
    "        species_list.append(full_mock_dict[key].description.split(' ')[1])\n",
    "all_values_dict = {}\n",
    "\n",
    "for species in species_list:\n",
    "    taxfileid = getquery_taxfileid(ref_df, species)\n",
    "    query_tax_dict = get_taxid_dict(mock_taxonomy_file_fn, taxfileid)\n",
    "    all_values_dict[species] = query_tax_dict,{'k': 0, 'p': 0, 'c': 0, 'o': 0, 'f': 0, 'g': 0, 's': 0}\n",
    "# print(all_values_dict)\n",
    "        \n",
    "    \n",
    "    \n",
    "for i in range(0, len(full_mock_dict.keys())):\n",
    "    # for i in range(600,800):\n",
    "    # adjust the range here to test for candida species\n",
    "    # as described in ranges in the above cell\n",
    "    print('%s/%s' % (i+1,len(full_mock_dict.keys())))\n",
    "    key = list(full_mock_dict.keys())[i]\n",
    "    species_name = full_mock_dict[key].description.split(' ')[1]\n",
    "    if i == 0 or i % 1000 == 0:\n",
    "        print(species_name)\n",
    "    max_len = len(full_mock_dict[key].seq)\n",
    "\n",
    "    # convert base pair coding to numerical coding and \n",
    "    # pad to the max sequence length\n",
    "    n_reads = 1\n",
    "    \n",
    "    numSeqIO_dicts = {}\n",
    "    numSeqIO_dicts[key] = numberfy(full_mock_dict[key], max_len, n_reads, species_name)\n",
    "    seq_list = []\n",
    "    for key in numSeqIO_dicts.keys():\n",
    "        seq_list.append(np.array(list(numSeqIO_dicts[key].values())))\n",
    "#     print(seq_list)\n",
    "\n",
    "    all_data = np.concatenate(seq_list)\n",
    "    num_class = len(numSeqIO_dicts)\n",
    "\n",
    "#     print('all_data.shape:', all_data.shape)\n",
    "    \n",
    "    samples_count = n_reads*num_class\n",
    "\n",
    "    # # Assign a percentage of data for training and the rest for testing\n",
    "    train_size = math.floor(1*all_data.shape[0])\n",
    "\n",
    "    # # Define the data vs labels for each of the training and test sets\n",
    "    X_test = all_data[:,:]\n",
    "\n",
    "#     print('X_test.shape : ', X_test.shape)\n",
    "\n",
    "#     print(ref_df[ref_df['species'] == species_name]['kingdom'].to_list()[0])\n",
    "    all_values_dict[species_name][1]['k'] += 1./n_per_species\n",
    "    \n",
    "    counter = 6\n",
    "    for tax_rank in tax_ranks:\n",
    "#         print('tax_rank =', tax_rank)\n",
    "        if tax_rank == 'kingdom':\n",
    "            model = load_model('../../analysis/models/model_%s_%s_15000.h5' % (tax_rank, 'fungi'))\n",
    "            classes = pd.read_csv('../../analysis/models/keys_%s_%s_15000.csv' % (tax_rank, 'fungi'), header=None)\n",
    "            classes.columns = ['predict','pred_name']\n",
    "            scores = model.predict(np.expand_dims(X_test,2))\n",
    "            predicts = model.predict_classes(np.expand_dims(X_test,2))\n",
    "            predicted_class = classes[classes['predict'] == predicts[0]]['pred_name'].to_list()[0]\n",
    "#             print('Predicted class is', predicted_class)\n",
    "\n",
    "#             print(ref_df[ref_df.iloc[:,1] == species_name].iloc[:,counter].to_list()[0])\n",
    "            if ref_df[ref_df.iloc[:,1] == species_name].iloc[:,counter].to_list()[0] == predicted_class:\n",
    "                all_values_dict[species_name][1][ref_df[ref_df.iloc[:,1] == species_name].columns[counter][0]] += 1./n_per_species\n",
    "            counter -= 1\n",
    "            keras.backend.clear_session()\n",
    "        elif tax_rank == 'genus':\n",
    "            if predicted_class not in nodes['tax_name'].values:\n",
    "                # then add 1 to each correct count if correct\n",
    "                predicted_class = large_ref_df[large_ref_df[tax_rank] == predicted_class].iloc[:,counter].to_list()[0]\n",
    "#                 print('Predicted class is', predicted_class)\n",
    "\n",
    "#                 print(ref_df[ref_df.iloc[:,1] == species_name].iloc[:,counter].to_list()[0])\n",
    "                if ref_df[ref_df.iloc[:,1] == species_name].iloc[:,counter].to_list()[0].split('_')[1] == predicted_class:\n",
    "                    all_values_dict[species_name][1][ref_df[ref_df.iloc[:,1] == species_name].columns[counter][0]] += 1./n_per_species\n",
    "                counter -= 1\n",
    "                keras.backend.clear_session()\n",
    "            else:\n",
    "                classes = pd.read_csv('../../analysis/models/keys_%s_%s_15000.csv' % (tax_rank, predicted_class), header=None)\n",
    "                classes.columns = ['predict','pred_name']\n",
    "#                 print('../../analysis/models/model_%s_%s_15000.h5' % (tax_rank, predicted_class))\n",
    "                model = load_model('../../analysis/models/model_%s_%s_15000.h5' % (tax_rank, predicted_class))\n",
    "                scores = model.predict(np.expand_dims(X_test,2))\n",
    "                predicts = model.predict_classes(np.expand_dims(X_test,2))\n",
    "                predicted_class = classes[classes['predict'] == predicts[0]]['pred_name'].to_list()[0]\n",
    "#                 print('Predicted class is', predicted_class)\n",
    "\n",
    "#                 print(ref_df[ref_df.iloc[:,1] == species_name].iloc[:,counter].to_list()[0])\n",
    "                if ref_df[ref_df.iloc[:,1] == species_name].iloc[:,counter].to_list()[0].split('_')[1] == predicted_class:\n",
    "                    all_values_dict[species_name][1][ref_df[ref_df.iloc[:,1] == species_name].columns[counter][0]] += 1./n_per_species\n",
    "                counter -= 1\n",
    "                keras.backend.clear_session()\n",
    "        else:\n",
    "            if predicted_class not in nodes['tax_name'].values:\n",
    "                # then add 1 to each correct count if correct\n",
    "#                 print(large_ref_df[large_ref_df[tax_rank] == predicted_class].iloc[:,counter].to_list())\n",
    "#                 print(predicted_class)\n",
    "                predicted_class = large_ref_df[large_ref_df[tax_rank] == predicted_class].iloc[:,counter].to_list()[0]\n",
    "#                 print('Predicted class is', predicted_class)\n",
    "\n",
    "#                 print(ref_df[ref_df.iloc[:,1] == species_name].iloc[:,counter].to_list()[0])\n",
    "                if ref_df[ref_df.iloc[:,1] == species_name].iloc[:,counter].to_list()[0] == predicted_class:\n",
    "                    all_values_dict[species_name][1][ref_df[ref_df.iloc[:,1] == species_name].columns[counter][0]] += 1./n_per_species\n",
    "                counter -= 1\n",
    "                keras.backend.clear_session()\n",
    "            else:\n",
    "                classes = pd.read_csv('../../analysis/models/keys_%s_%s_15000.csv' % (tax_rank, predicted_class), header=None)\n",
    "                classes.columns = ['predict','pred_name']\n",
    "#                 print('../../analysis/models/model_%s_%s_15000.h5' % (tax_rank, predicted_class))\n",
    "                model = load_model('../../analysis/models/model_%s_%s_15000.h5' % (tax_rank, predicted_class))\n",
    "                scores = model.predict(np.expand_dims(X_test,2))\n",
    "                predicts = model.predict_classes(np.expand_dims(X_test,2))\n",
    "                predicted_class = classes[classes['predict'] == predicts[0]]['pred_name'].to_list()[0]\n",
    "#                 print('Predicted class is', predicted_class)\n",
    "\n",
    "#                 print(ref_df[ref_df.iloc[:,1] == species_name].iloc[:,counter].to_list()[0])\n",
    "                if ref_df[ref_df.iloc[:,1] == species_name].iloc[:,counter].to_list()[0] == predicted_class:\n",
    "                    all_values_dict[species_name][1][ref_df[ref_df.iloc[:,1] == species_name].columns[counter][0]] += 1./n_per_species\n",
    "                counter -= 1\n",
    "                keras.backend.clear_session()\n",
    "#     print(all_values_dict[species_name][1])\n",
    "    if (i+1) % 1000 == 0:\n",
    "        print(all_values_dict[species_name][1])\n",
    "        with open('/media/MassStorage/tmp/TE/honours/analysis/Mapping/mock/ML_results/%s.json' % species_name, 'w+') as fp:\n",
    "            json.dump(all_values_dict[species_name][1], fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
